      save_best: True
      plot_agents: True

      logger:
            classname: bbrl.utils.logger.TFLogger
            log_dir: ./ppo_logs/
            verbose: False
            every_n_seconds: 10

      algorithm:
            seed: 5
            max_grad_norm: 0.5
            n_envs: 2
            n_steps: 100
            eval_interval: 1000
            nb_evals: 10
            gae: 0.95
            max_epochs: 20
            discount_factor: 0.9
            clip_range: 0.2
            clip_range_vf: 0
            entropy_coef: 2e-7
            critic_coef: 0.4
            policy_coef: 1
            opt_epochs: 3
            batch_size: 16
            beta: 0.0
            policy_type: TunableVariancePPOActor
            architecture:
                  policy_hidden_size: [64, 64]
                  critic_hidden_size: [64, 64]

      gym_env:
            classname: __main__.make_gym_env
            env_name: SingleStateMDP-v0

      optimizer:
            classname: torch.optim.Adam
            lr: 0.001